{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_size = 224\n",
    "model_path = './models/efficientnet-b3-3000.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('idx2class3000.pkl', 'rb') as f:\n",
    "    class_names = pickle.load(f)\n",
    "\n",
    "model_test = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "num_ftrs = model_test._fc.in_features\n",
    "\n",
    "model_test._fc  = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model_test.to(device)\n",
    "\n",
    "model_test.load_state_dict(torch.load(model_path))\n",
    "model_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.Resize((input_size, input_size)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.726, 0.686, 0.695], [0.205, 0.210, 0.183])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_model(model, input_image_path):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with Image.open(input_image_path) as input_image:\n",
    "            resized_image = data_transforms(input_image).unsqueeze(0).to(device)\n",
    "            \n",
    "            output = model(resized_image)\n",
    "            _, pred = torch.max(output, 1)\n",
    "            softmax = nn.Softmax(dim=1)\n",
    "            prob_output = softmax(output)\n",
    "            prob, pred = torch.max(prob_output, 1)\n",
    "        model.train(mode=was_training)\n",
    "    \n",
    "    return pred.item(), prob.item(), np.array(prob_output.cpu())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "\n",
    "test_dir = './model_data/test/'\n",
    "test_img_paths = []\n",
    "for root, dirs, files in os.walk(test_dir):\n",
    "    for name in files:\n",
    "        label = root.replace(test_dir, '')\n",
    "        test_img_paths.append((label, os.path.join(root, name)))\n",
    "random.shuffle(test_img_paths)\n",
    "\n",
    "thresholds = np.array([0.0, 0.3, 0.5, 0.7, 0.8])\n",
    "test_preds = [[] for _ in range(len(thresholds))]\n",
    "test_labels = []\n",
    "\n",
    "for (label, img_path)  in test_img_paths:\n",
    "    pred, max_prob, probs = inference_model(model_test, img_path)\n",
    "    for i in range(len(thresholds)):\n",
    "        if max_prob < thresholds[i]:\n",
    "            test_preds[i].append('isnull')\n",
    "        else:\n",
    "            test_preds[i].append(class_names[pred])\n",
    "    test_labels.append(label)\n",
    "\n",
    "for i in range(len(thresholds)):\n",
    "    report = classification_report(test_labels, test_preds[i], output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df.to_csv('./result/model_3000_threshold_{}.csv'.format(str(thresholds[i]).replace('.', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = './esun_data/test/'\n",
    "test_img_paths = []\n",
    "for root, dirs, files in os.walk(test_dir):\n",
    "    for name in files:\n",
    "        label = root.replace(test_dir, '')\n",
    "        test_img_paths.append((label, os.path.join(root, name)))\n",
    "random.shuffle(test_img_paths)\n",
    "\n",
    "with open('wordset800.txt', 'r') as f:\n",
    "    wordset = f.read().split('\\n')\n",
    "\n",
    "thresholds = np.array([0.0, 0.3, 0.5, 0.7, 0.8])\n",
    "test_preds = [[] for _ in range(len(thresholds))]\n",
    "test_labels = []\n",
    "\n",
    "for (label, img_path)  in test_img_paths:\n",
    "    pred, max_prob, probs = inference_model(model_test, img_path)\n",
    "\n",
    "    for i in range(len(thresholds)):\n",
    "        if max_prob < thresholds[i]:\n",
    "            test_preds[i].append('isnull')\n",
    "        else:\n",
    "            if class_names[pred] in wordset:\n",
    "                test_preds[i].append(class_names[pred])\n",
    "            else:\n",
    "                test_preds[i].append('isnull')\n",
    "    test_labels.append(label)\n",
    "\n",
    "for i in range(len(thresholds)):\n",
    "    report = classification_report(test_labels, test_preds[i], output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df.to_csv('./result/esun_data_model_3000_threshold_{}.csv'.format(str(thresholds[i]).replace('.', '')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
